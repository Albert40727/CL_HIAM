{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python38\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "configuration = BertConfig()\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True).to(device)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', use_fast=True)\n",
    "args = {\n",
    "        \"device\" : device,\n",
    "        \"data_dir\" : r'../data/filtered_reviews_with_split.pkl',\n",
    "        \"data_chunks_dir\" : r'../data/chunks',\n",
    "        \"emb_dim\" : 768,\n",
    "        \"max_word\" : 25,\n",
    "        \"max_sentence\" : 10,\n",
    "        \"max_review_user\" : 10,\n",
    "        \"max_review_item\" : 30,\n",
    "        \"epoch\" : 5,\n",
    "        \"batch_size\": 32,\n",
    "        \"bert_configuration\" : configuration,\n",
    "        \"bert_model\" : bert_model,\n",
    "        \"bert_tokenizer\" : bert_tokenizer\n",
    "    }\n",
    "\n",
    "print(\"Device: \",device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AppID               int32\n",
      "UserID              int64\n",
      "Like                int32\n",
      "Review             object\n",
      "SplitReview        object\n",
      "SplitReview_emb    object\n",
      "LDA_group          object\n",
      "dtype: object\n",
      "Once you've prepared the data, press {Run All} will do the megic\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AppID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>Like</th>\n",
       "      <th>Review</th>\n",
       "      <th>SplitReview</th>\n",
       "      <th>SplitReview_emb</th>\n",
       "      <th>LDA_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561197996720254</td>\n",
       "      <td>1</td>\n",
       "      <td>[h1]We're all sus![/h1]\\n\\n[b][u]PROS[/u]:[/b]...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561198133726836</td>\n",
       "      <td>1</td>\n",
       "      <td>buy this on steam for free fortnite skin</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561198271396832</td>\n",
       "      <td>1</td>\n",
       "      <td>honesty gets you voted off when you're not eve...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561198083568932</td>\n",
       "      <td>0</td>\n",
       "      <td>An international sensation, yet receives updat...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561198123845513</td>\n",
       "      <td>1</td>\n",
       "      <td>[h1] [b] Sus [/b] [/h1]\\n\\nOverall Review: Red...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23873</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198069159152</td>\n",
       "      <td>1</td>\n",
       "      <td>So this game has been rumbling around a bit on...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23874</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198304467388</td>\n",
       "      <td>1</td>\n",
       "      <td>Simple story yet heartful and warm love story ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23875</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198009282696</td>\n",
       "      <td>1</td>\n",
       "      <td>A little heartwarming story about two sisters....</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23876</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198120348301</td>\n",
       "      <td>1</td>\n",
       "      <td>Razz’s art style just keeps getting better and...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23877</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198097675823</td>\n",
       "      <td>1</td>\n",
       "      <td>Love Ribbon is a great visual novel, now to th...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23878 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AppID             UserID  Like  \\\n",
       "0      945360  76561197996720254     1   \n",
       "1      945360  76561198133726836     1   \n",
       "2      945360  76561198271396832     1   \n",
       "3      945360  76561198083568932     0   \n",
       "4      945360  76561198123845513     1   \n",
       "...       ...                ...   ...   \n",
       "23873  559610  76561198069159152     1   \n",
       "23874  559610  76561198304467388     1   \n",
       "23875  559610  76561198009282696     1   \n",
       "23876  559610  76561198120348301     1   \n",
       "23877  559610  76561198097675823     1   \n",
       "\n",
       "                                                  Review SplitReview  \\\n",
       "0      [h1]We're all sus![/h1]\\n\\n[b][u]PROS[/u]:[/b]...               \n",
       "1               buy this on steam for free fortnite skin               \n",
       "2      honesty gets you voted off when you're not eve...               \n",
       "3      An international sensation, yet receives updat...               \n",
       "4      [h1] [b] Sus [/b] [/h1]\\n\\nOverall Review: Red...               \n",
       "...                                                  ...         ...   \n",
       "23873  So this game has been rumbling around a bit on...               \n",
       "23874  Simple story yet heartful and warm love story ...               \n",
       "23875  A little heartwarming story about two sisters....               \n",
       "23876  Razz’s art style just keeps getting better and...               \n",
       "23877  Love Ribbon is a great visual novel, now to th...               \n",
       "\n",
       "      SplitReview_emb LDA_group  \n",
       "0                                \n",
       "1                                \n",
       "2                                \n",
       "3                                \n",
       "4                                \n",
       "...               ...       ...  \n",
       "23873                            \n",
       "23874                            \n",
       "23875                            \n",
       "23876                            \n",
       "23877                            \n",
       "\n",
       "[23878 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Required dataframe format:\n",
    "[column name]       [dtype]\n",
    "AppID               int\n",
    "UserID              int\n",
    "Like                int\n",
    "Review              String\n",
    "\"\"\"\n",
    "data = pd.read_pickle(r'../data/review_data_casual.pkl')\n",
    "# Change dtype of columns in df\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data[\"UserID\"] = data[\"UserID\"].astype(\"int64\")\n",
    "data[\"AppID\"] = data[\"AppID\"].astype(int)\n",
    "data[\"Like\"] = data[\"Like\"].astype(int)\n",
    "\"\"\"\n",
    "TODO dataframe format:\n",
    "[column name]       [dtype]\n",
    "SplitReview         list\n",
    "LDA_group           list\n",
    "SplitReview_emb     np.array\n",
    "\"\"\"\n",
    "# TODO Columns\n",
    "data[\"SplitReview\"] = \"\"\n",
    "data[\"SplitReview_emb\"]=\"\"\n",
    "data[\"LDA_group\"]=\"\"\n",
    "\n",
    "print(data.dtypes)\n",
    "print(\"Once you've prepared the data, press {Run All} will do the megic\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265890     209\n",
       " 945360     201\n",
       " 533300     201\n",
       " 435400     192\n",
       " 1794680    191\n",
       "           ... \n",
       " 1106840     18\n",
       " 606800      18\n",
       " 761830      18\n",
       " 1009560     17\n",
       " 1224160     16\n",
       " Name: AppID, Length: 485, dtype: int64,\n",
       " 76561198027267313    80\n",
       " 76561198040884867    75\n",
       " 76561198062813911    68\n",
       " 76561197987731882    62\n",
       " 76561198069159152    62\n",
       "                      ..\n",
       " 76561198041024658     6\n",
       " 76561198086933786     6\n",
       " 76561197985573260     6\n",
       " 76561198048974498     6\n",
       " 76561198353593495     6\n",
       " Name: UserID, Length: 1679, dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 確定 threshold 後檢查有多少個 App、User\n",
    "app_reviews = data['AppID'].value_counts()\n",
    "user_reviews = data['UserID'].value_counts()\n",
    "app_reviews, user_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Split every review to sentences.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def review_to_sentences(review):\n",
    "    \"\"\"\n",
    "    split review into sentences contained by a list\n",
    "    param: review (String)\n",
    "    output: sentences (list of word)\n",
    "    \"\"\"\n",
    "    sentences = review.splitlines()\n",
    "    sentences = list(filter(None, sentences))\n",
    "    tmp = []\n",
    "    for sent in sentences:\n",
    "        sent = re.split(r' *[\\.\\?!][\\'\"\\)\\]]* *', sent)\n",
    "        tmp.extend(sent)\n",
    "    # delete sentence less than specific number of words\n",
    "    sentences = list(filter(lambda x:len(x.split())>=5, tmp))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AppID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>Like</th>\n",
       "      <th>Review</th>\n",
       "      <th>SplitReview</th>\n",
       "      <th>SplitReview_emb</th>\n",
       "      <th>LDA_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561197996720254</td>\n",
       "      <td>1</td>\n",
       "      <td>[h1]We're all sus![/h1]\\n\\n[b][u]PROS[/u]:[/b]...</td>\n",
       "      <td>[[b][u]PROS[/u]:[/b] Among Us is a social dedu...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561198133726836</td>\n",
       "      <td>1</td>\n",
       "      <td>buy this on steam for free fortnite skin</td>\n",
       "      <td>[buy this on steam for free fortnite skin]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561198271396832</td>\n",
       "      <td>1</td>\n",
       "      <td>honesty gets you voted off when you're not eve...</td>\n",
       "      <td>[honesty gets you voted off when you're not ev...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561198083568932</td>\n",
       "      <td>0</td>\n",
       "      <td>An international sensation, yet receives updat...</td>\n",
       "      <td>[An international sensation, yet receives upda...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561198123845513</td>\n",
       "      <td>1</td>\n",
       "      <td>[h1] [b] Sus [/b] [/h1]\\n\\nOverall Review: Red...</td>\n",
       "      <td>[[h1] [b] Sus [/b] [/h1], Overall Review: Red ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22930</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198069159152</td>\n",
       "      <td>1</td>\n",
       "      <td>So this game has been rumbling around a bit on...</td>\n",
       "      <td>[So this game has been rumbling around a bit o...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22931</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198304467388</td>\n",
       "      <td>1</td>\n",
       "      <td>Simple story yet heartful and warm love story ...</td>\n",
       "      <td>[Simple story yet heartful and warm love story...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22932</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198009282696</td>\n",
       "      <td>1</td>\n",
       "      <td>A little heartwarming story about two sisters....</td>\n",
       "      <td>[A little heartwarming story about two sisters...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22933</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198120348301</td>\n",
       "      <td>1</td>\n",
       "      <td>Razz’s art style just keeps getting better and...</td>\n",
       "      <td>[Razz’s art style just keeps getting better an...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22934</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198097675823</td>\n",
       "      <td>1</td>\n",
       "      <td>Love Ribbon is a great visual novel, now to th...</td>\n",
       "      <td>[Love Ribbon is a great visual novel, now to t...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22935 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AppID             UserID  Like  \\\n",
       "0      945360  76561197996720254     1   \n",
       "1      945360  76561198133726836     1   \n",
       "2      945360  76561198271396832     1   \n",
       "3      945360  76561198083568932     0   \n",
       "4      945360  76561198123845513     1   \n",
       "...       ...                ...   ...   \n",
       "22930  559610  76561198069159152     1   \n",
       "22931  559610  76561198304467388     1   \n",
       "22932  559610  76561198009282696     1   \n",
       "22933  559610  76561198120348301     1   \n",
       "22934  559610  76561198097675823     1   \n",
       "\n",
       "                                                  Review  \\\n",
       "0      [h1]We're all sus![/h1]\\n\\n[b][u]PROS[/u]:[/b]...   \n",
       "1               buy this on steam for free fortnite skin   \n",
       "2      honesty gets you voted off when you're not eve...   \n",
       "3      An international sensation, yet receives updat...   \n",
       "4      [h1] [b] Sus [/b] [/h1]\\n\\nOverall Review: Red...   \n",
       "...                                                  ...   \n",
       "22930  So this game has been rumbling around a bit on...   \n",
       "22931  Simple story yet heartful and warm love story ...   \n",
       "22932  A little heartwarming story about two sisters....   \n",
       "22933  Razz’s art style just keeps getting better and...   \n",
       "22934  Love Ribbon is a great visual novel, now to th...   \n",
       "\n",
       "                                             SplitReview SplitReview_emb  \\\n",
       "0      [[b][u]PROS[/u]:[/b] Among Us is a social dedu...                   \n",
       "1             [buy this on steam for free fortnite skin]                   \n",
       "2      [honesty gets you voted off when you're not ev...                   \n",
       "3      [An international sensation, yet receives upda...                   \n",
       "4      [[h1] [b] Sus [/b] [/h1], Overall Review: Red ...                   \n",
       "...                                                  ...             ...   \n",
       "22930  [So this game has been rumbling around a bit o...                   \n",
       "22931  [Simple story yet heartful and warm love story...                   \n",
       "22932  [A little heartwarming story about two sisters...                   \n",
       "22933  [Razz’s art style just keeps getting better an...                   \n",
       "22934  [Love Ribbon is a great visual novel, now to t...                   \n",
       "\n",
       "      LDA_group  \n",
       "0                \n",
       "1                \n",
       "2                \n",
       "3                \n",
       "4                \n",
       "...         ...  \n",
       "22930            \n",
       "22931            \n",
       "22932            \n",
       "22933            \n",
       "22934            \n",
       "\n",
       "[22935 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_split_sentences =  [review_to_sentences(review) for review in data[\"Review\"]]\n",
    "data[\"SplitReview\"] = list_split_sentences\n",
    "empty = [i for i, x in enumerate(data[\"SplitReview\"]) if x ==[]] # Delete data whose splitReview is empty list\n",
    "data.drop(empty, axis=0, inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LDA Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify 趙儀's LDA part\n",
    "def stemmer_with_delete_stopword(split_sentences):\n",
    "    vectorizer = TfidfVectorizer(stop_words = \"english\")\n",
    "    stop_list = list(vectorizer.get_stop_words())\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    all_stem_sents=[]\n",
    "    for review in split_sentences:\n",
    "        review_stem_list = []\n",
    "        for sent in review:\n",
    "            sent_stem_list =[]\n",
    "            for word in sent.split(\" \"):\n",
    "                if len(word)>2:\n",
    "                    if word not in stop_list:\n",
    "                        sent_stem_list.append(porter_stemmer.stem(word))\n",
    "            review_stem_list.append(sent_stem_list)\n",
    "        all_stem_sents.append(review_stem_list) \n",
    "    return all_stem_sents\n",
    "\n",
    "def LDAGrouping(reviews):\n",
    "    all_sents = []\n",
    "    for review in reviews:\n",
    "        for sentence in review:\n",
    "            all_sents.append(sentence)\n",
    "    dictionary = corpora.Dictionary(all_sents)\n",
    "    corpus = [dictionary.doc2bow(sent) for sent in all_sents]\n",
    "    lda = models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=5)\n",
    "    group_results = []\n",
    "    for sents in reviews:\n",
    "        single_corpus = [dictionary.doc2bow(sent) for sent in sents]\n",
    "        sents_group_result = []\n",
    "        for scores in lda.inference(single_corpus)[0]:\n",
    "            # scores.argmax()+1 --> Retain group:0 for no meaning sentences\n",
    "            sents_group_result.append(scores.argmax()+1)\n",
    "        group_results.append(sents_group_result)\n",
    "\n",
    "    return group_results\n",
    "\n",
    "def pad_and_trunc(group_results, *, max_sentence):\n",
    "    #max number of sentences in a review\n",
    "    result_list = []\n",
    "    for i, result in enumerate(group_results):\n",
    "        if len(result) >= max_sentence:\n",
    "            result = result[:10]\n",
    "        else:\n",
    "            result.extend([0]*(max_sentence-len(result)))\n",
    "        result_list.append(np.array(result).astype(int))\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AppID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>Like</th>\n",
       "      <th>Review</th>\n",
       "      <th>SplitReview</th>\n",
       "      <th>SplitReview_emb</th>\n",
       "      <th>LDA_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561197996720254</td>\n",
       "      <td>1</td>\n",
       "      <td>[h1]We're all sus![/h1]\\n\\n[b][u]PROS[/u]:[/b]...</td>\n",
       "      <td>[[b][u]PROS[/u]:[/b] Among Us is a social dedu...</td>\n",
       "      <td></td>\n",
       "      <td>[5, 1, 1, 4, 4, 5, 3, 3, 5, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561198133726836</td>\n",
       "      <td>1</td>\n",
       "      <td>buy this on steam for free fortnite skin</td>\n",
       "      <td>[buy this on steam for free fortnite skin]</td>\n",
       "      <td></td>\n",
       "      <td>[5, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561198271396832</td>\n",
       "      <td>1</td>\n",
       "      <td>honesty gets you voted off when you're not eve...</td>\n",
       "      <td>[honesty gets you voted off when you're not ev...</td>\n",
       "      <td></td>\n",
       "      <td>[2, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561198083568932</td>\n",
       "      <td>0</td>\n",
       "      <td>An international sensation, yet receives updat...</td>\n",
       "      <td>[An international sensation, yet receives upda...</td>\n",
       "      <td></td>\n",
       "      <td>[1, 5, 1, 1, 3, 3, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561198123845513</td>\n",
       "      <td>1</td>\n",
       "      <td>[h1] [b] Sus [/b] [/h1]\\n\\nOverall Review: Red...</td>\n",
       "      <td>[[h1] [b] Sus [/b] [/h1], Overall Review: Red ...</td>\n",
       "      <td></td>\n",
       "      <td>[4, 2, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22930</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198069159152</td>\n",
       "      <td>1</td>\n",
       "      <td>So this game has been rumbling around a bit on...</td>\n",
       "      <td>[So this game has been rumbling around a bit o...</td>\n",
       "      <td></td>\n",
       "      <td>[3, 1, 1, 1, 2, 2, 1, 5, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22931</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198304467388</td>\n",
       "      <td>1</td>\n",
       "      <td>Simple story yet heartful and warm love story ...</td>\n",
       "      <td>[Simple story yet heartful and warm love story...</td>\n",
       "      <td></td>\n",
       "      <td>[2, 4, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22932</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198009282696</td>\n",
       "      <td>1</td>\n",
       "      <td>A little heartwarming story about two sisters....</td>\n",
       "      <td>[A little heartwarming story about two sisters...</td>\n",
       "      <td></td>\n",
       "      <td>[2, 5, 4, 2, 5, 2, 1, 4, 2, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22933</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198120348301</td>\n",
       "      <td>1</td>\n",
       "      <td>Razz’s art style just keeps getting better and...</td>\n",
       "      <td>[Razz’s art style just keeps getting better an...</td>\n",
       "      <td></td>\n",
       "      <td>[4, 5, 5, 2, 2, 5, 5, 3, 4, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22934</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198097675823</td>\n",
       "      <td>1</td>\n",
       "      <td>Love Ribbon is a great visual novel, now to th...</td>\n",
       "      <td>[Love Ribbon is a great visual novel, now to t...</td>\n",
       "      <td></td>\n",
       "      <td>[3, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22935 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AppID             UserID  Like  \\\n",
       "0      945360  76561197996720254     1   \n",
       "1      945360  76561198133726836     1   \n",
       "2      945360  76561198271396832     1   \n",
       "3      945360  76561198083568932     0   \n",
       "4      945360  76561198123845513     1   \n",
       "...       ...                ...   ...   \n",
       "22930  559610  76561198069159152     1   \n",
       "22931  559610  76561198304467388     1   \n",
       "22932  559610  76561198009282696     1   \n",
       "22933  559610  76561198120348301     1   \n",
       "22934  559610  76561198097675823     1   \n",
       "\n",
       "                                                  Review  \\\n",
       "0      [h1]We're all sus![/h1]\\n\\n[b][u]PROS[/u]:[/b]...   \n",
       "1               buy this on steam for free fortnite skin   \n",
       "2      honesty gets you voted off when you're not eve...   \n",
       "3      An international sensation, yet receives updat...   \n",
       "4      [h1] [b] Sus [/b] [/h1]\\n\\nOverall Review: Red...   \n",
       "...                                                  ...   \n",
       "22930  So this game has been rumbling around a bit on...   \n",
       "22931  Simple story yet heartful and warm love story ...   \n",
       "22932  A little heartwarming story about two sisters....   \n",
       "22933  Razz’s art style just keeps getting better and...   \n",
       "22934  Love Ribbon is a great visual novel, now to th...   \n",
       "\n",
       "                                             SplitReview SplitReview_emb  \\\n",
       "0      [[b][u]PROS[/u]:[/b] Among Us is a social dedu...                   \n",
       "1             [buy this on steam for free fortnite skin]                   \n",
       "2      [honesty gets you voted off when you're not ev...                   \n",
       "3      [An international sensation, yet receives upda...                   \n",
       "4      [[h1] [b] Sus [/b] [/h1], Overall Review: Red ...                   \n",
       "...                                                  ...             ...   \n",
       "22930  [So this game has been rumbling around a bit o...                   \n",
       "22931  [Simple story yet heartful and warm love story...                   \n",
       "22932  [A little heartwarming story about two sisters...                   \n",
       "22933  [Razz’s art style just keeps getting better an...                   \n",
       "22934  [Love Ribbon is a great visual novel, now to t...                   \n",
       "\n",
       "                            LDA_group  \n",
       "0      [5, 1, 1, 4, 4, 5, 3, 3, 5, 4]  \n",
       "1      [5, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2      [2, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3      [1, 5, 1, 1, 3, 3, 0, 0, 0, 0]  \n",
       "4      [4, 2, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                               ...  \n",
       "22930  [3, 1, 1, 1, 2, 2, 1, 5, 0, 0]  \n",
       "22931  [2, 4, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "22932  [2, 5, 4, 2, 5, 2, 1, 4, 2, 4]  \n",
       "22933  [4, 5, 5, 2, 2, 5, 5, 3, 4, 4]  \n",
       "22934  [3, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[22935 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_reviews = stemmer_with_delete_stopword(data[\"SplitReview\"].tolist())\n",
    "group_list = LDAGrouping(clean_reviews) # Training might take a little bit time \n",
    "pad_group_list = pad_and_trunc(group_list, max_sentence=args[\"max_sentence\"])\n",
    "data[\"LDA_group\"] = pad_group_list\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the LDA grouping result\n",
    "data.to_pickle(r\"../data/filtered_reviews_group.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train Val Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15339, 2014, 5582, 22935)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split train/val/test data by user case\n",
    "train_df, val_df, test_df = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "tain_ratio = 0.7\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "for user in set(data[\"UserID\"]):\n",
    "    single_user_data = data[data[\"UserID\"]==user]\n",
    "    single_user_data_train = single_user_data[:int(len(single_user_data)*tain_ratio)]\n",
    "    single_user_data_val = single_user_data[int(len(single_user_data)*tain_ratio):int(len(single_user_data)*(tain_ratio+val_ratio))]\n",
    "    single_user_data_test = single_user_data[int(len(single_user_data)*(tain_ratio+val_ratio)):]\n",
    "    train_df = pd.concat([train_df, single_user_data_train], axis=0)\n",
    "    val_df = pd.concat([val_df, single_user_data_val], axis=0)\n",
    "    test_df = pd.concat([test_df, single_user_data_test], axis=0)\n",
    "len(train_df), len(val_df), len(test_df), len(train_df)+len(val_df)+len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving three types of dataframe\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "train_df.to_pickle(r\"../data/train_df.pkl\")\n",
    "val_df.to_pickle(r\"../data/val_df.pkl\")\n",
    "test_df.to_pickle(r\"../data/test_df.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Encode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Init Bert and encode methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_to_tagert_dimension(input_tensor, sent_len, word_len, word_dim):\n",
    "    \"\"\"\n",
    "    Set input_tensor to specified dim with zero padding, and flatten it\n",
    "    ex: [3, 25, 768] -> [10, 25, 768] -> [250, 768]\n",
    "    \"\"\"\n",
    "    target_emb = torch.zeros(sent_len, word_len, word_dim)\n",
    "    target_emb[:input_tensor.size(dim=0), :, :] = input_tensor\n",
    "    target_emb = torch.flatten(target_emb, start_dim=0, end_dim=1)\n",
    "    \n",
    "    return target_emb\n",
    "\n",
    "def bert_encode(review_split, args):\n",
    "    \"\"\"\n",
    "    Encode splitted review to bert embedding\n",
    "    return embedding of review padded with zero\n",
    "    \"\"\"\n",
    "    emb_list = []\n",
    "    for i, sentence in enumerate(review_split):\n",
    "        if i == args[\"max_sentence\"]: break\n",
    "        sentence_encode = args[\"bert_tokenizer\"](\n",
    "            sentence,\n",
    "            return_attention_mask = True,\n",
    "            max_length = args[\"max_word\"],\n",
    "            truncation = True,\n",
    "            padding = \"max_length\",\n",
    "            return_tensors = 'pt'\n",
    "            )\n",
    "        for k,v in sentence_encode.items():\n",
    "            sentence_encode[k] = v.to(args[\"device\"])\n",
    "        with torch.no_grad():\n",
    "            outputs = args[\"bert_model\"](**sentence_encode)\n",
    "        sentence_emb = outputs[2][-1]\n",
    "        emb_list.append(sentence_emb)\n",
    "    review_emb = torch.cat(emb_list, 0)\n",
    "    pad_review_emb = padding_to_tagert_dimension(review_emb, args[\"max_sentence\"], args[\"max_word\"], args[\"emb_dim\"])\n",
    "    return pad_review_emb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Encode splited sentences and save into multiple chunks of H5DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving emb for each \"user\"\n",
    "def save_each_bert_emb(data, *, col_name, target):\n",
    "    user_set_len = len(set(data[col_name]))\n",
    "    for i, indie in enumerate(set(data[col_name])):\n",
    "        print(\"執行%s進度: %d/%d\\r\"%(target, i, user_set_len), end=\"\")\n",
    "        user_data = data[data[col_name]==indie]\n",
    "        for index, review in zip(user_data.index, user_data[\"SplitReview\"]):\n",
    "            review_emb = np.asarray(bert_encode(review, args))\n",
    "            user_data.at[index, \"SplitReview_emb\"] = review_emb\n",
    "            user_data[[\"SplitReview_emb\", \"LDA_group\"]].to_pickle(f'../data/{target}_emb/{indie}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "執行user進度: 1672/1673\r"
     ]
    }
   ],
   "source": [
    "# This step require a lot of disk storage. Please make sure that you have sufficient space.\n",
    "save_each_bert_emb(data, col_name=\"UserID\", target=\"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "執行item進度: 484/485\r"
     ]
    }
   ],
   "source": [
    "# This step require a lot of disk storage. Please make sure that you have sufficient space.\n",
    "#  Can't store all emb into one df, so it has to be run twice \n",
    "save_each_bert_emb(data, col_name=\"AppID\", target=\"item\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Show Bert Encode Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 250, 768])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 76561198066129673 garbage reviewer\n",
    "tmp = pd.read_pickle(r\"../data/item_emb/3300.pkl\")\n",
    "torch.from_numpy(np.array(tmp[\"SplitReview_emb\"].tolist())).size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AppID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>Like</th>\n",
       "      <th>Interacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561197996720254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561198133726836</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561198271396832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561198083568932</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>945360</td>\n",
       "      <td>76561198123845513</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22930</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198069159152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22931</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198304467388</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22932</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198009282696</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22933</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198120348301</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22934</th>\n",
       "      <td>559610</td>\n",
       "      <td>76561198097675823</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22935 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AppID             UserID  Like  Interacted\n",
       "0      945360  76561197996720254     1           1\n",
       "1      945360  76561198133726836     1           1\n",
       "2      945360  76561198271396832     1           1\n",
       "3      945360  76561198083568932     0           1\n",
       "4      945360  76561198123845513     1           1\n",
       "...       ...                ...   ...         ...\n",
       "22930  559610  76561198069159152     1           1\n",
       "22931  559610  76561198304467388     1           1\n",
       "22932  559610  76561198009282696     1           1\n",
       "22933  559610  76561198120348301     1           1\n",
       "22934  559610  76561198097675823     1           1\n",
       "\n",
       "[22935 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_df = pd.read_pickle(r\"../data/filtered_reviews_group.pkl\")\n",
    "mf_df = mf_df[['AppID', 'UserID', 'Like']]\n",
    "mf_df['Interacted'] = 1\n",
    "mf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify MF From 裴伯儀\n",
    "def train_test_random_split(df):\n",
    "    app_ids = list(df.columns)\n",
    "    user_ids = list(df.index)\n",
    "    user_set = {}\n",
    "    for user_id in user_ids:\n",
    "        interacted_items = [app_ids[idx] for idx in df.loc[user_id].values.nonzero()[0].tolist()]\n",
    "        user_set[user_id] = interacted_items\n",
    "    return user_set\n",
    "\n",
    "def get_trainVector(df, user_set):\n",
    "    business_ids = list(df.columns)\n",
    "    user_ids = list(df.index)\n",
    "    return [ [1 if business_id in user_set[user_id] else 0 for business_id in business_ids ] for user_id in user_ids]\n",
    "\n",
    "def matrix_factorization(matrix, trainVector):\n",
    "    # n_components is embedding dimension, vervose=1 shows the training process\n",
    "    model = NMF(n_components=128, init='random', random_state=0, verbose=0)\n",
    "    user_embeddings = model.fit_transform(trainVector*matrix.values)\n",
    "    encoded_user_embeddings = np.asarray(user_embeddings, dtype=np.float32)\n",
    "    app_embeddings = model.components_.T\n",
    "    encoded_app_embeddings = np.asarray(app_embeddings.astype('float32'))\n",
    "    user_id_emb = dict(zip(matrix.index, encoded_user_embeddings))\n",
    "    app_id_emb = dict(zip(matrix.columns, encoded_app_embeddings))\n",
    "    \n",
    "    return user_id_emb, app_id_emb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Rating Matrix and Interaction Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_matrix = mf_df.pivot_table(index='UserID', columns='AppID', values='Interacted').fillna(0)\n",
    "rating_matrix = mf_df.pivot_table(index='UserID', columns='AppID', values='Like').fillna(0)\n",
    "user_set = train_test_random_split(interaction_matrix)\n",
    "trainVector = torch.tensor(get_trainVector(interaction_matrix, user_set)).to(torch.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train MF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1673, 485, (128,), (128,))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_emb, app_id_emb = matrix_factorization(rating_matrix, trainVector)\n",
    "len(user_id_emb), len(app_id_emb), next(iter(user_id_emb.values())).shape, next(iter(app_id_emb.values())).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save MF Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_mf_df = pd.DataFrame()\n",
    "app_mf_df[\"AppID\"] = list(app_id_emb.keys())\n",
    "app_mf_df[\"MF_emb\"] = list(app_id_emb.values())\n",
    "app_mf_df.to_pickle(r\"../data/train_item_mf_emb.pkl\")\n",
    "\n",
    "user_mf_df = pd.DataFrame()\n",
    "user_mf_df[\"UserID\"] = list(user_id_emb.keys())\n",
    "user_mf_df[\"MF_emb\"] = list(user_id_emb.values())\n",
    "user_mf_df.to_pickle(r\"../data/train_user_mf_emb.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1600, 250, 768])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.reshape(torch.randn((32,50,250,768)), (1600,250,768)).size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f5363c3ed6ceeb7d7f17727abd6f7f46ae0b682ea370b1a2b2638e5ad156f3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
